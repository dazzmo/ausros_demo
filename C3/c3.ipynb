{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Packages\n",
    "For this lectorial, we will investigate various control strategies for controlling articulated rigid body systems. This example set is written in Python 3, presented as a Jupyter notebook.\n",
    "\n",
    "We will be making strong use of the open-source rigid-body dynamics library [Pinocchio](https://github.com/stack-of-tasks/pinocchio), as it will allow us to efficiently compute a number of kinodynamic expressions related to robotics and control.\n",
    "\n",
    "To install Pinocchio in Python, we will be using `pip`, and it can be installed with the command\n",
    "```python\n",
    "pip install pin\n",
    "```\n",
    "\n",
    "We will also install a set of example robotics systems (containing URDF files and their accompanying visual and geometric files)\n",
    "\n",
    "```python\n",
    "pip install example-robot-data\n",
    "```\n",
    "\n",
    "And for visualisation of these models, the visualisation library Meshcat\n",
    "\n",
    "```python\n",
    "pip install meshcat\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Example\n",
    "Here we will load the manipulator [Panda](https://robodk.com/robot/Franka/Emika-Panda) and load it into the Meshcat visualiser with a desired configuration. You should see a new window open in your browser displaying the Panda arm in its default state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7005/static/\n"
     ]
    }
   ],
   "source": [
    "import pinocchio as pin\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from example_robot_data import load\n",
    "\n",
    "robot = load('panda')\n",
    "\n",
    "# Select the default configuration for the robot.\n",
    "q0 = robot.q0\n",
    "# OPTIONAL - Instead, choose a random configuration within the configuration space of the model\n",
    "# q0 = pin.randomConfiguration(robot.model)\n",
    "\n",
    "## visualise the robot\n",
    "import meshcat\n",
    "from pinocchio.visualize import MeshcatVisualizer\n",
    "viz = MeshcatVisualizer(robot.model, robot.collision_model, robot.visual_model)\n",
    "# Start a new MeshCat server and client.\n",
    "viz.initViewer(open=True)\n",
    "# Load the robot in the viewer.\n",
    "viz.loadViewerModel()\n",
    "# Display the robot with the initial state q0\n",
    "viz.display(q0)\n",
    "\n",
    "# Display reference as a transparent red model\n",
    "viz_ref = MeshcatVisualizer(robot.model, robot.collision_model, robot.visual_model)\n",
    "viz_ref.initViewer(viz.viewer)\n",
    "viz_ref.loadViewerModel(rootNodeName=\"referemce\", color=[1.0, 0.0, 0.0, 0.1])\n",
    "\n",
    "# small time window for loading the model \n",
    "# if meshcat does not visualise the robot properly, augment the time\n",
    "# it can be removed in most cases\n",
    "time.sleep(0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating the Dynamics Without Control\n",
    "We will now use the rigid-body dynamics algorithms to forward-compute the dynamics of the robot from an initial state. When there is no joint stiffness or damping, the system will behave chaotically.\n",
    "\n",
    "We are not accounting for collisions in this tutorial, as this would require a sophisticated physic simulator to handle the dynamics of contact, Meshcat is simply displaying the configuration of the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reference_generator(robot, t):\n",
    "    qr = robot.q0\n",
    "    # Provide sinusoidal generation to select joints\n",
    "    qr[0] = np.sin(t)\n",
    "    qr[2] = np.sin(t)\n",
    "    qr[3] = np.sin(t)\n",
    "    \n",
    "    vr = np.zeros(robot.nv)\n",
    "    \n",
    "    return (qr, vr)\n",
    "\n",
    "\n",
    "# Control inputs to each joint of the robot (set to zero) \n",
    "u = np.zeros(robot.nq)\n",
    "\n",
    "# This is a very basic forward-simulator of the dynamics of the system given a control law controller, where the dynamics are forward-stepped by a first-order approximation.\n",
    "def simulate(T, dt, robot, viz, viz_ref, controller, fps = 30):\n",
    "    frame_cnt = 0\n",
    "\n",
    "    # nq - Dimension of the robots configuration vector q\n",
    "    # nv - Dimension of the robots velocity and acceleration vectors (v, a)\n",
    "    \n",
    "    q = robot.q0 # Configuration vector q\n",
    "    v = np.zeros(robot.nv) # Velocity vector v\n",
    "    a = np.zeros(robot.nv) # Acceleration vector a\n",
    "\n",
    "    # Determine number of steps to wait until next frame\n",
    "    n_skip = int((1.0 / fps) / dt)\n",
    "\n",
    "    t = 0\n",
    "    while t <= T:\n",
    "        # Compute controller for current instanct\n",
    "        u = controller(robot, t, q, v)\n",
    "        # Calculate the current acceleration of the robot given the configuration, velocity and input\n",
    "        a = pin.aba(robot.model, robot.data, q, v, u)\n",
    "        # Forward step\n",
    "        v = v + dt * a\n",
    "        q = q + dt * v\n",
    "        \n",
    "        t += dt\n",
    "        \n",
    "        # Display every 24 frames\n",
    "        if frame_cnt % n_skip == 0:\n",
    "            viz.display(q)\n",
    "            viz_ref.display(robot.q0)\n",
    "            time.sleep(1.0 / fps)\n",
    "        \n",
    "        frame_cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with simulating the system with no control input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_control(robot, t, q, v):\n",
    "    return np.zeros(robot.nv)\n",
    "\n",
    "# Simulator step resolution (s)\n",
    "dt = 0.001\n",
    "\n",
    "# Simulate the system for 5 seconds\n",
    "simulate(5.0, dt, robot, viz, viz_ref, null_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PD Joint Control\n",
    "To track a nominal state, we can introduce virtual spring-damping to each joint by using a PD controller to act at each joint proportional to the error and error rate at each time step, much like in Lecture 1. \n",
    "\n",
    "<b>Note :</b> We are not using integral control here for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control Law u = Kp (q - qr) + Kd (v - vr)\n",
    "def pd_controller(robot, t, q, v):\n",
    "    # Define a reference\n",
    "    qr, vr = reference_generator(robot, t)\n",
    "    # Define gains\n",
    "    Kp = np.diag([20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0])\n",
    "    Kd = np.diag([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "\n",
    "    return  Kp.dot(qr - q) + Kd.dot(vr - v)\n",
    "\n",
    "# Simulate the system for 5 seconds\n",
    "simulate(5.0, dt, robot, viz, viz_ref, pd_controller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computed Torque Control\n",
    "That wasn't very good, was it? It looks as though our controller doesn't know the robot arm has weight, which is exactly what is happening. Let us instead view the controller from an acceleration perspective, if we can compute torques that achieve a desired acceleration in the joints, we can make this desired acceleration our error terms. We can then choose accelerations that are dynamically consistent with the robot, such that they also account for the dynamics of the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def computed_torque_controller(robot, t, q, v):\n",
    "    # Define a reference\n",
    "    qr, vr = reference_generator(robot, t)\n",
    "    ar = np.zeros(robot.nv)\n",
    "\n",
    "    Kp = np.diag([20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0])\n",
    "    Kd = np.diag([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "\n",
    "    # Set desired acceleration of the system as the PD error of the state\n",
    "    ad = ar + Kp.dot(qr - q) + Kd.dot(vr - v)\n",
    "    # Compute control inputs that would realise this acceleration on the model, accounting for its dynamics\n",
    "    u = pin.rnea(robot.model, robot.data, q, v, ad)\n",
    "    \n",
    "    return  u\n",
    "\n",
    "# Simulate the system for 5 seconds\n",
    "simulate(5.0, dt, robot, viz, viz_ref, computed_torque_controller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the dynamics are now accounted for in the controller, thus the robot hardly moves. It should be noted this is a perfect simulation, where we know the dynamics of the robot exactly, if the models differ significantly, the behaviour may grow unstable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operational Space Control\n",
    "Moving the arm to any arbitrary point in space can be difficult from a computed torque perspective, as we need to know what joint configuration is required. \n",
    "\n",
    "Operational space control allows us to specify tasks that the robot needs to perform, and computes a torque to achieve it. This can range from positional tasks and impedance control (specify a desired force or spring-damper-like behaviour) to more abstract goals such as stability criterion and centre of mass tracking.\n",
    "\n",
    "Continuing with our Panda example, we will make the robot follow a specified trajectory in space using operational space control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include symbolic algebra package Casadi\n",
    "from casadi import *\n",
    "\n",
    "def operational_space_control(robot, q, v):\n",
    "    # Compute the positions of all bodies in the robot by using forward kinematics\n",
    "    pin.forwardKinematics(robot.model, robot.data, q)\n",
    "    # Joint ID\n",
    "    JOINT_ID = 8\n",
    "\n",
    "    # Compute task-space acceleration\n",
    "    M = pin.crba(robot.model, robot.data, q)\n",
    "    h = pin.rnea(robot.model, robot.data, q, v, np.zeros(robot.nq))\n",
    "    \n",
    "    # Track the position of the tip of the robot\n",
    "    x = robot.data.oMi[JOINT_ID].translation\n",
    "    # Get the Jacobian of the position in space\n",
    "    J = pin.computeJointJacobian(robot.model, robot.data, q, JOINT_ID)[3:6, :]\n",
    "    # Get the time-rate of change of the derivative\n",
    "    pin.computeJointJacobiansTimeVariation(robot.model, robot.data, q, v)\n",
    "    dJ = pin.getJointJacobianTimeVariation(robot.model, robot.data, JOINT_ID, pin.LOCAL)\n",
    "\n",
    "\n",
    "\n",
    "    # Compute task-space control\n",
    "\n",
    "\n",
    "    return np.zeros(robot.nv)\n",
    "\n",
    "simulate(5.0, dt, robot, viz, operational_space_control)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Predictive Control\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
